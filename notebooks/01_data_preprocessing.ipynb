{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c6cbb9",
   "metadata": {},
   "source": [
    "# Flight Price Forecast - Data Preprocessing\n",
    "\n",
    "This notebook handles the data preprocessing phase of the Flight Price Forecasting project. We will:\n",
    "\n",
    "- Load and inspect the US Airline Flight Routes and Fares dataset (1993-2024)\n",
    "- Clean the data by removing duplicates and handling errors\n",
    "- Filter and keep only relevant features\n",
    "- Export the cleaned dataset for subsequent analysis\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Objective**: Predict airline fare trends using historical data from 1993-2024  \n",
    "**Dataset**: US Airline Flight Routes and Fares from Kaggle  \n",
    "**Methodology**: Data-driven approach with machine learning models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40dca3",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d4bc8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T23:42:56.833155Z",
     "iopub.status.busy": "2025-11-18T23:42:56.833155Z",
     "iopub.status.idle": "2025-11-18T23:42:57.642685Z",
     "shell.execute_reply": "2025-11-18T23:42:57.642685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.2.3\n",
      "NumPy version: 1.26.3\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File operations\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better data viewing\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842e6a2",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ead785b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T23:42:57.643826Z",
     "iopub.status.busy": "2025-11-18T23:42:57.643826Z",
     "iopub.status.idle": "2025-11-18T23:42:57.981569Z",
     "shell.execute_reply": "2025-11-18T23:42:57.981066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset shape: (245955, 23)\n",
      "Rows: 245,955\n",
      "Columns: 23\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = \"../US Airline Flight Routes and Fares 1993-2024.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Rows: {df.shape[0]:,}\")\n",
    "    print(f\"Columns: {df.shape[1]}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Dataset not found at {data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b73bd6c",
   "metadata": {},
   "source": [
    "## 3. Initial Data Inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786d6e36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T23:42:57.982574Z",
     "iopub.status.busy": "2025-11-18T23:42:57.982574Z",
     "iopub.status.idle": "2025-11-18T23:42:58.159124Z",
     "shell.execute_reply": "2025-11-18T23:42:58.159124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DATASET OVERVIEW\n",
      "==================================================\n",
      "Dataset shape: (245955, 23)\n",
      "Memory usage: 194.92 MB\n",
      "\n",
      "Column names and types:\n",
      "tbl                object\n",
      "Year                int64\n",
      "quarter             int64\n",
      "citymarketid_1      int64\n",
      "citymarketid_2      int64\n",
      "city1              object\n",
      "city2              object\n",
      "airportid_1         int64\n",
      "airportid_2         int64\n",
      "airport_1          object\n",
      "airport_2          object\n",
      "nsmiles             int64\n",
      "passengers          int64\n",
      "fare              float64\n",
      "carrier_lg         object\n",
      "large_ms          float64\n",
      "fare_lg           float64\n",
      "carrier_low        object\n",
      "lf_ms             float64\n",
      "fare_low          float64\n",
      "Geocoded_City1     object\n",
      "Geocoded_City2     object\n",
      "tbl1apk            object\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tbl</th>\n",
       "      <th>Year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>citymarketid_1</th>\n",
       "      <th>citymarketid_2</th>\n",
       "      <th>city1</th>\n",
       "      <th>city2</th>\n",
       "      <th>airportid_1</th>\n",
       "      <th>airportid_2</th>\n",
       "      <th>airport_1</th>\n",
       "      <th>airport_2</th>\n",
       "      <th>nsmiles</th>\n",
       "      <th>passengers</th>\n",
       "      <th>fare</th>\n",
       "      <th>carrier_lg</th>\n",
       "      <th>large_ms</th>\n",
       "      <th>fare_lg</th>\n",
       "      <th>carrier_low</th>\n",
       "      <th>lf_ms</th>\n",
       "      <th>fare_low</th>\n",
       "      <th>Geocoded_City1</th>\n",
       "      <th>Geocoded_City2</th>\n",
       "      <th>tbl1apk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Table1a</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>30135</td>\n",
       "      <td>33195</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA</td>\n",
       "      <td>Tampa, FL (Metropolitan Area)</td>\n",
       "      <td>10135</td>\n",
       "      <td>14112</td>\n",
       "      <td>ABE</td>\n",
       "      <td>PIE</td>\n",
       "      <td>970</td>\n",
       "      <td>180</td>\n",
       "      <td>81.43</td>\n",
       "      <td>G4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>81.43</td>\n",
       "      <td>G4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>81.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202131013514112ABEPIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Table1a</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>30135</td>\n",
       "      <td>33195</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA</td>\n",
       "      <td>Tampa, FL (Metropolitan Area)</td>\n",
       "      <td>10135</td>\n",
       "      <td>15304</td>\n",
       "      <td>ABE</td>\n",
       "      <td>TPA</td>\n",
       "      <td>970</td>\n",
       "      <td>19</td>\n",
       "      <td>208.93</td>\n",
       "      <td>DL</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>219.98</td>\n",
       "      <td>UA</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>154.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202131013515304ABETPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Table1a</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>30140</td>\n",
       "      <td>30194</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>10140</td>\n",
       "      <td>11259</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>DAL</td>\n",
       "      <td>580</td>\n",
       "      <td>204</td>\n",
       "      <td>184.56</td>\n",
       "      <td>WN</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>184.44</td>\n",
       "      <td>WN</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>184.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202131014011259ABQDAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Table1a</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>30140</td>\n",
       "      <td>30194</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>10140</td>\n",
       "      <td>11298</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>DFW</td>\n",
       "      <td>580</td>\n",
       "      <td>264</td>\n",
       "      <td>182.64</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>183.09</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>183.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202131014011298ABQDFW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Table1a</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>30140</td>\n",
       "      <td>30466</td>\n",
       "      <td>Albuquerque, NM</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>10140</td>\n",
       "      <td>14107</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>PHX</td>\n",
       "      <td>328</td>\n",
       "      <td>398</td>\n",
       "      <td>177.11</td>\n",
       "      <td>WN</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>184.49</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.3939</td>\n",
       "      <td>165.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202131014014107ABQPHX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tbl  Year  quarter  citymarketid_1  citymarketid_2  \\\n",
       "0  Table1a  2021        3           30135           33195   \n",
       "1  Table1a  2021        3           30135           33195   \n",
       "2  Table1a  2021        3           30140           30194   \n",
       "3  Table1a  2021        3           30140           30194   \n",
       "4  Table1a  2021        3           30140           30466   \n",
       "\n",
       "                            city1                          city2  airportid_1  \\\n",
       "0  Allentown/Bethlehem/Easton, PA  Tampa, FL (Metropolitan Area)        10135   \n",
       "1  Allentown/Bethlehem/Easton, PA  Tampa, FL (Metropolitan Area)        10135   \n",
       "2                 Albuquerque, NM          Dallas/Fort Worth, TX        10140   \n",
       "3                 Albuquerque, NM          Dallas/Fort Worth, TX        10140   \n",
       "4                 Albuquerque, NM                    Phoenix, AZ        10140   \n",
       "\n",
       "   airportid_2 airport_1 airport_2  nsmiles  passengers    fare carrier_lg  \\\n",
       "0        14112       ABE       PIE      970         180   81.43         G4   \n",
       "1        15304       ABE       TPA      970          19  208.93         DL   \n",
       "2        11259       ABQ       DAL      580         204  184.56         WN   \n",
       "3        11298       ABQ       DFW      580         264  182.64         AA   \n",
       "4        14107       ABQ       PHX      328         398  177.11         WN   \n",
       "\n",
       "   large_ms  fare_lg carrier_low   lf_ms  fare_low Geocoded_City1  \\\n",
       "0    1.0000    81.43          G4  1.0000     81.43            NaN   \n",
       "1    0.4659   219.98          UA  0.1193    154.11            NaN   \n",
       "2    0.9968   184.44          WN  0.9968    184.44            NaN   \n",
       "3    0.9774   183.09          AA  0.9774    183.09            NaN   \n",
       "4    0.6061   184.49          AA  0.3939    165.77            NaN   \n",
       "\n",
       "  Geocoded_City2                tbl1apk  \n",
       "0            NaN  202131013514112ABEPIE  \n",
       "1            NaN  202131013515304ABETPA  \n",
       "2            NaN  202131014011259ABQDAL  \n",
       "3            NaN  202131014011298ABQDFW  \n",
       "4            NaN  202131014014107ABQPHX  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tbl</th>\n",
       "      <th>Year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>citymarketid_1</th>\n",
       "      <th>citymarketid_2</th>\n",
       "      <th>city1</th>\n",
       "      <th>city2</th>\n",
       "      <th>airportid_1</th>\n",
       "      <th>airportid_2</th>\n",
       "      <th>airport_1</th>\n",
       "      <th>airport_2</th>\n",
       "      <th>nsmiles</th>\n",
       "      <th>passengers</th>\n",
       "      <th>fare</th>\n",
       "      <th>carrier_lg</th>\n",
       "      <th>large_ms</th>\n",
       "      <th>fare_lg</th>\n",
       "      <th>carrier_low</th>\n",
       "      <th>lf_ms</th>\n",
       "      <th>fare_low</th>\n",
       "      <th>Geocoded_City1</th>\n",
       "      <th>Geocoded_City2</th>\n",
       "      <th>tbl1apk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245950</th>\n",
       "      <td>Table1a</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>35412</td>\n",
       "      <td>31703</td>\n",
       "      <td>Knoxville, TN</td>\n",
       "      <td>New York City, NY (Metropolitan Area)</td>\n",
       "      <td>15412</td>\n",
       "      <td>12953</td>\n",
       "      <td>TYS</td>\n",
       "      <td>LGA</td>\n",
       "      <td>665</td>\n",
       "      <td>207</td>\n",
       "      <td>278.70</td>\n",
       "      <td>DL</td>\n",
       "      <td>0.7503</td>\n",
       "      <td>287.44</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.2359</td>\n",
       "      <td>248.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411541212953TYSLGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245951</th>\n",
       "      <td>Table1a</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>35412</td>\n",
       "      <td>32467</td>\n",
       "      <td>Knoxville, TN</td>\n",
       "      <td>Miami, FL (Metropolitan Area)</td>\n",
       "      <td>15412</td>\n",
       "      <td>11697</td>\n",
       "      <td>TYS</td>\n",
       "      <td>FLL</td>\n",
       "      <td>724</td>\n",
       "      <td>277</td>\n",
       "      <td>148.69</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.8255</td>\n",
       "      <td>114.45</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.8255</td>\n",
       "      <td>114.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411541211697TYSFLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245952</th>\n",
       "      <td>Table1a</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>35412</td>\n",
       "      <td>32467</td>\n",
       "      <td>Knoxville, TN</td>\n",
       "      <td>Miami, FL (Metropolitan Area)</td>\n",
       "      <td>15412</td>\n",
       "      <td>13303</td>\n",
       "      <td>TYS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>724</td>\n",
       "      <td>70</td>\n",
       "      <td>330.19</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>321.92</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>321.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411541213303TYSMIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245953</th>\n",
       "      <td>Table1a</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>35412</td>\n",
       "      <td>33195</td>\n",
       "      <td>Knoxville, TN</td>\n",
       "      <td>Tampa, FL (Metropolitan Area)</td>\n",
       "      <td>15412</td>\n",
       "      <td>14112</td>\n",
       "      <td>TYS</td>\n",
       "      <td>PIE</td>\n",
       "      <td>550</td>\n",
       "      <td>178</td>\n",
       "      <td>95.65</td>\n",
       "      <td>G4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>95.65</td>\n",
       "      <td>G4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>95.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411541214112TYSPIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245954</th>\n",
       "      <td>Table1a</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>35412</td>\n",
       "      <td>33195</td>\n",
       "      <td>Knoxville, TN</td>\n",
       "      <td>Tampa, FL (Metropolitan Area)</td>\n",
       "      <td>15412</td>\n",
       "      <td>15304</td>\n",
       "      <td>TYS</td>\n",
       "      <td>TPA</td>\n",
       "      <td>550</td>\n",
       "      <td>57</td>\n",
       "      <td>330.15</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>288.38</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>288.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202411541215304TYSTPA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tbl  Year  quarter  citymarketid_1  citymarketid_2          city1  \\\n",
       "245950  Table1a  2024        1           35412           31703  Knoxville, TN   \n",
       "245951  Table1a  2024        1           35412           32467  Knoxville, TN   \n",
       "245952  Table1a  2024        1           35412           32467  Knoxville, TN   \n",
       "245953  Table1a  2024        1           35412           33195  Knoxville, TN   \n",
       "245954  Table1a  2024        1           35412           33195  Knoxville, TN   \n",
       "\n",
       "                                        city2  airportid_1  airportid_2  \\\n",
       "245950  New York City, NY (Metropolitan Area)        15412        12953   \n",
       "245951          Miami, FL (Metropolitan Area)        15412        11697   \n",
       "245952          Miami, FL (Metropolitan Area)        15412        13303   \n",
       "245953          Tampa, FL (Metropolitan Area)        15412        14112   \n",
       "245954          Tampa, FL (Metropolitan Area)        15412        15304   \n",
       "\n",
       "       airport_1 airport_2  nsmiles  passengers    fare carrier_lg  large_ms  \\\n",
       "245950       TYS       LGA      665         207  278.70         DL    0.7503   \n",
       "245951       TYS       FLL      724         277  148.69         G4    0.8255   \n",
       "245952       TYS       MIA      724          70  330.19         AA    0.8057   \n",
       "245953       TYS       PIE      550         178   95.65         G4    1.0000   \n",
       "245954       TYS       TPA      550          57  330.15         AA    0.5212   \n",
       "\n",
       "        fare_lg carrier_low   lf_ms  fare_low Geocoded_City1 Geocoded_City2  \\\n",
       "245950   287.44          AA  0.2359    248.46            NaN            NaN   \n",
       "245951   114.45          G4  0.8255    114.45            NaN            NaN   \n",
       "245952   321.92          AA  0.8057    321.92            NaN            NaN   \n",
       "245953    95.65          G4  1.0000     95.65            NaN            NaN   \n",
       "245954   288.38          AA  0.5212    288.38            NaN            NaN   \n",
       "\n",
       "                      tbl1apk  \n",
       "245950  202411541212953TYSLGA  \n",
       "245951  202411541211697TYSFLL  \n",
       "245952  202411541213303TYSMIA  \n",
       "245953  202411541214112TYSPIE  \n",
       "245954  202411541215304TYSTPA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"=\"*50)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if 'df' in locals():\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(\"\\nColumn names and types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "\n",
    "    print(f\"\\nLast 5 rows:\")\n",
    "    display(df.tail())\n",
    "else:\n",
    "    print(\"Dataset not loaded. Please run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d760f38",
   "metadata": {},
   "source": [
    "## 4. Data Quality Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c4b7873",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T23:42:58.160127Z",
     "iopub.status.busy": "2025-11-18T23:42:58.160127Z",
     "iopub.status.idle": "2025-11-18T23:42:58.465986Z",
     "shell.execute_reply": "2025-11-18T23:42:58.465986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING VALUES ANALYSIS"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values summary:\n",
      "            Column  Missing Count  Missing Percentage\n",
      "21  Geocoded_City2          39206           15.940314\n",
      "20  Geocoded_City1          39206           15.940314\n",
      "19        fare_low           1612            0.655404\n",
      "18           lf_ms           1612            0.655404\n",
      "17     carrier_low           1612            0.655404\n",
      "16         fare_lg           1540            0.626131\n",
      "15        large_ms           1540            0.626131\n",
      "14      carrier_lg           1540            0.626131\n",
      "\n",
      "\n",
      "DUPLICATE RECORDS\n",
      "==================================================\n",
      "Total duplicate rows: 0\n",
      "Percentage of duplicates: 0.00%\n",
      "\n",
      "\n",
      "DATA TYPES ANALYSIS\n",
      "==================================================\n",
      "Current data types:\n",
      "tbl                object\n",
      "Year                int64\n",
      "quarter             int64\n",
      "citymarketid_1      int64\n",
      "citymarketid_2      int64\n",
      "city1              object\n",
      "city2              object\n",
      "airportid_1         int64\n",
      "airportid_2         int64\n",
      "airport_1          object\n",
      "airport_2          object\n",
      "nsmiles             int64\n",
      "passengers          int64\n",
      "fare              float64\n",
      "carrier_lg         object\n",
      "large_ms          float64\n",
      "fare_lg           float64\n",
      "carrier_low        object\n",
      "lf_ms             float64\n",
      "fare_low          float64\n",
      "Geocoded_City1     object\n",
      "Geocoded_City2     object\n",
      "tbl1apk            object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "STATISTICAL SUMMARY\n",
      "==================================================\n",
      "Numerical columns summary:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Year        quarter  citymarketid_1  citymarketid_2  \\\n",
      "count  245955.000000  245955.000000   245955.000000   245955.000000   \n",
      "mean     2008.524124       2.479153    31556.430201    32180.117086   \n",
      "std         8.703364       1.122149     1089.872880     1232.464184   \n",
      "min      1993.000000       1.000000    30135.000000    30189.000000   \n",
      "25%      2001.000000       1.000000    30721.000000    30994.000000   \n",
      "50%      2008.000000       2.000000    31423.000000    32211.000000   \n",
      "75%      2016.000000       3.000000    32467.000000    33192.000000   \n",
      "max      2024.000000       4.000000    35412.000000    35628.000000   \n",
      "\n",
      "         airportid_1    airportid_2        nsmiles     passengers  \\\n",
      "count  245955.000000  245955.000000  245955.000000  245955.000000   \n",
      "mean    12437.099986   13249.889525    1189.812319     299.476795   \n",
      "std      1431.665257    1425.810159     703.143472     511.389486   \n",
      "min     10135.000000   10466.000000     109.000000       0.000000   \n",
      "25%     11193.000000   12197.000000     626.000000      21.000000   \n",
      "50%     12266.000000   13303.000000    1023.000000     113.000000   \n",
      "75%     13487.000000   14679.000000    1736.000000     339.000000   \n",
      "max     16440.000000   15919.000000    2724.000000    8301.000000   \n",
      "\n",
      "                fare       large_ms        fare_lg          lf_ms  \\\n",
      "count  245955.000000  244415.000000  244415.000000  244343.000000   \n",
      "mean      218.979587       0.665252     218.710963       0.450438   \n",
      "std        82.372486       0.224635      84.674363       0.332669   \n",
      "min        50.000000       0.003800      50.000000       0.010000   \n",
      "25%       164.620000       0.480000     161.500000       0.158000   \n",
      "50%       209.320000       0.652400     208.030000       0.360000   \n",
      "75%       262.890000       0.871900     263.640000       0.750000   \n",
      "max      3377.000000       1.000000    2725.600000       1.000000   \n",
      "\n",
      "            fare_low  \n",
      "count  244343.000000  \n",
      "mean      190.675939  \n",
      "std        73.577694  \n",
      "min        50.000000  \n",
      "25%       140.060000  \n",
      "50%       181.630000  \n",
      "75%       230.040000  \n",
      "max      2725.600000  \n",
      "\n",
      "\n",
      "OUTLIER DETECTION (Basic)\n",
      "==================================================\n",
      "Year: 0 potential outliers (0.00%)\n",
      "quarter: 0 potential outliers (0.00%)\n",
      "citymarketid_1: 1644 potential outliers (0.67%)\n",
      "citymarketid_2: 0 potential outliers (0.00%)\n",
      "airportid_1: 0 potential outliers (0.00%)\n",
      "\n",
      "✓ Data quality assessment completed!\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Missing Percentage': missing_percentage.values\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(\"Missing values summary:\")\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\n\\nDUPLICATE RECORDS\")\n",
    "print(\"=\"*50)\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Total duplicate rows: {duplicates}\")\n",
    "print(f\"Percentage of duplicates: {(duplicates/len(df)*100):.2f}%\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"\\nSample duplicate rows:\")\n",
    "    print(df[df.duplicated()].head())\n",
    "\n",
    "# Check data types\n",
    "print(f\"\\n\\nDATA TYPES ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "print(\"Current data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Statistical summary\n",
    "print(f\"\\n\\nSTATISTICAL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(\"Numerical columns summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for potential outliers (basic analysis)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "if len(numeric_cols) > 0:\n",
    "    print(f\"\\n\\nOUTLIER DETECTION (Basic)\")\n",
    "    print(\"=\"*50)\n",
    "    for col in numeric_cols[:5]:  # Check first 5 numeric columns\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "        print(\n",
    "            f\"{col}: {len(outliers)} potential outliers ({len(outliers)/len(df)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n✓ Data quality assessment completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42d88b",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad14e6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T23:42:58.466988Z",
     "iopub.status.busy": "2025-11-18T23:42:58.466988Z",
     "iopub.status.idle": "2025-11-18T23:42:59.298099Z",
     "shell.execute_reply": "2025-11-18T23:42:59.298099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING DATA CLEANING PROCESS\n",
      "==================================================\n",
      "Original dataset shape: (245955, 23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Duplicate removal:\n",
      "   - Removed 0 duplicate rows\n",
      "   - New shape: (245955, 23)\n",
      "\n",
      "2. Missing value treatment:\n",
      "   - Columns with missing values: ['carrier_lg', 'large_ms', 'fare_lg', 'carrier_low', 'lf_ms', 'fare_low', 'Geocoded_City1', 'Geocoded_City2']\n",
      "   - Missing values before: 87868\n",
      "   - Missing values after: 0\n",
      "   - New shape: (205189, 23)\n",
      "\n",
      "3. Data type optimization:\n",
      "   Current dtypes:\n",
      "   - tbl: object\n",
      "   - Year: int64\n",
      "   - quarter: int64\n",
      "   - citymarketid_1: int64\n",
      "   - citymarketid_2: int64\n",
      "   - city1: object\n",
      "   - city2: object\n",
      "   - airportid_1: int64\n",
      "   - airportid_2: int64\n",
      "   - airport_1: object\n",
      "   - airport_2: object\n",
      "   - nsmiles: int64\n",
      "   - passengers: int64\n",
      "   - fare: float64\n",
      "   - carrier_lg: object\n",
      "   - large_ms: float64\n",
      "   - fare_lg: float64\n",
      "   - carrier_low: object\n",
      "   - lf_ms: float64\n",
      "   - fare_low: float64\n",
      "   - Geocoded_City1: object\n",
      "   - Geocoded_City2: object\n",
      "   - tbl1apk: object\n",
      "   - Converted tbl to category\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Converted city1 to category\n",
      "   - Converted city2 to category\n",
      "   - Converted airport_1 to category\n",
      "   - Converted airport_2 to category\n",
      "   - Converted carrier_lg to category\n",
      "   - Converted carrier_low to category\n",
      "   - Converted Geocoded_City1 to category\n",
      "   - Converted Geocoded_City2 to category\n",
      "\n",
      "4. Basic outlier removal:\n",
      "   - citymarketid_1: Removed 1349 outliers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - passengers: Removed 20130 outliers\n",
      "   - fare: Removed 3561 outliers\n",
      "   - fare_lg: Removed 1567 outliers\n",
      "   - fare_low: Removed 1600 outliers\n",
      "   - Total outliers removed: 28207\n",
      "   - New shape: (176982, 23)\n",
      "\n",
      "5. Final data validation:\n",
      "   - Final shape: (176982, 23)\n",
      "   - Rows removed: 68973 (28.04%)\n",
      "   - Columns retained: 23/23\n",
      "   - Memory usage: 34.55 MB\n",
      "\n",
      "✓ Data cleaning completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "original_shape = df_clean.shape\n",
    "\n",
    "print(\"STARTING DATA CLEANING PROCESS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original dataset shape: {original_shape}\")\n",
    "\n",
    "# Step 1: Remove duplicates\n",
    "duplicates_removed = df_clean.duplicated().sum()\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "print(f\"\\n1. Duplicate removal:\")\n",
    "print(f\"   - Removed {duplicates_removed} duplicate rows\")\n",
    "print(f\"   - New shape: {df_clean.shape}\")\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "print(f\"\\n2. Missing value treatment:\")\n",
    "missing_before = df_clean.isnull().sum().sum()\n",
    "\n",
    "# For demonstration, let's use a simple strategy\n",
    "# In practice, you'd analyze each column specifically\n",
    "columns_with_missing = df_clean.columns[df_clean.isnull().any()].tolist()\n",
    "if columns_with_missing:\n",
    "    print(f\"   - Columns with missing values: {columns_with_missing}\")\n",
    "\n",
    "    # Simple strategy: drop rows with any missing values\n",
    "    # You might want to implement more sophisticated strategies\n",
    "    df_clean = df_clean.dropna()\n",
    "\n",
    "missing_after = df_clean.isnull().sum().sum()\n",
    "print(f\"   - Missing values before: {missing_before}\")\n",
    "print(f\"   - Missing values after: {missing_after}\")\n",
    "print(f\"   - New shape: {df_clean.shape}\")\n",
    "\n",
    "# Step 3: Data type optimization\n",
    "print(f\"\\n3. Data type optimization:\")\n",
    "print(\"   Current dtypes:\")\n",
    "for col in df_clean.columns:\n",
    "    print(f\"   - {col}: {df_clean[col].dtype}\")\n",
    "\n",
    "# Convert object columns to category where appropriate (saves memory)\n",
    "object_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "for col in object_cols:\n",
    "    if df_clean[col].nunique() < len(df_clean) * 0.5:  # If less than 50% unique values\n",
    "        df_clean[col] = df_clean[col].astype('category')\n",
    "        print(f\"   - Converted {col} to category\")\n",
    "\n",
    "# Step 4: Remove obvious outliers (basic approach)\n",
    "print(f\"\\n4. Basic outlier removal:\")\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "outliers_removed_total = 0\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # Use IQR method for outlier detection\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers_before = len(df_clean)\n",
    "    df_clean = df_clean[(df_clean[col] >= lower_bound) &\n",
    "                        (df_clean[col] <= upper_bound)]\n",
    "    outliers_after = len(df_clean)\n",
    "    outliers_removed = outliers_before - outliers_after\n",
    "\n",
    "    if outliers_removed > 0:\n",
    "        print(f\"   - {col}: Removed {outliers_removed} outliers\")\n",
    "        outliers_removed_total += outliers_removed\n",
    "\n",
    "print(f\"   - Total outliers removed: {outliers_removed_total}\")\n",
    "print(f\"   - New shape: {df_clean.shape}\")\n",
    "\n",
    "# Step 5: Final validation\n",
    "print(f\"\\n5. Final data validation:\")\n",
    "print(f\"   - Final shape: {df_clean.shape}\")\n",
    "print(\n",
    "    f\"   - Rows removed: {original_shape[0] - df_clean.shape[0]} ({((original_shape[0] - df_clean.shape[0])/original_shape[0]*100):.2f}%)\")\n",
    "print(f\"   - Columns retained: {df_clean.shape[1]}/{original_shape[1]}\")\n",
    "print(\n",
    "    f\"   - Memory usage: {df_clean.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\n✓ Data cleaning completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60061319",
   "metadata": {},
   "source": [
    "## 6. Export Cleaned Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6267454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T23:42:59.299104Z",
     "iopub.status.busy": "2025-11-18T23:42:59.299104Z",
     "iopub.status.idle": "2025-11-18T23:43:00.127382Z",
     "shell.execute_reply": "2025-11-18T23:43:00.127382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPORTING CLEANED DATA\n",
      "==================================================\n",
      "✓ Cleaned dataset saved to: ../data/cleaned_data.csv\n",
      "✓ Shape: (176982, 23)\n",
      "✓ File size: 45.25 MB\n",
      "✓ Preprocessing summary saved to: ../data/preprocessing_summary.json\n",
      "\n",
      "============================================================\n",
      "DATA PREPROCESSING COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "Original dataset: 245,955 rows × 23 columns\n",
      "Cleaned dataset: 176,982 rows × 23 columns\n",
      "Rows removed: 68,973 (28.0%)\n",
      "Saved to: ../data/cleaned_data.csv\n",
      "Ready for exploratory data analysis!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "import json\n",
    "import os\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "# Save cleaned dataset\n",
    "cleaned_data_path = '../data/cleaned_data.csv'\n",
    "df_clean.to_csv(cleaned_data_path, index=False)\n",
    "\n",
    "print(\"EXPORTING CLEANED DATA\")\n",
    "print(\"=\"*50)\n",
    "print(f\"✓ Cleaned dataset saved to: {cleaned_data_path}\")\n",
    "print(f\"✓ Shape: {df_clean.shape}\")\n",
    "print(f\"✓ File size: {os.path.getsize(cleaned_data_path) / 1024**2:.2f} MB\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_stats = {\n",
    "    'original_shape': original_shape,\n",
    "    'cleaned_shape': df_clean.shape,\n",
    "    'rows_removed': original_shape[0] - df_clean.shape[0],\n",
    "    'percentage_retained': (df_clean.shape[0] / original_shape[0]) * 100,\n",
    "    'columns_info': {\n",
    "        'numeric': len(df_clean.select_dtypes(include=[np.number]).columns),\n",
    "        'categorical': len(df_clean.select_dtypes(include=['object', 'category']).columns),\n",
    "        'total': df_clean.shape[1]\n",
    "    },\n",
    "    'missing_values': df_clean.isnull().sum().sum(),\n",
    "    'memory_usage_mb': df_clean.memory_usage(deep=True).sum() / 1024**2\n",
    "}\n",
    "\n",
    "stats_path = '../data/preprocessing_summary.json'\n",
    "with open(stats_path, 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2, default=str)\n",
    "\n",
    "print(f\"✓ Preprocessing summary saved to: {stats_path}\")\n",
    "\n",
    "# Display final summary\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"DATA PREPROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"=\"*60)\n",
    "print(\n",
    "    f\"Original dataset: {original_shape[0]:,} rows × {original_shape[1]} columns\")\n",
    "print(\n",
    "    f\"Cleaned dataset: {df_clean.shape[0]:,} rows × {df_clean.shape[1]} columns\")\n",
    "print(\n",
    "    f\"Rows removed: {original_shape[0] - df_clean.shape[0]:,} ({((original_shape[0] - df_clean.shape[0])/original_shape[0]*100):.1f}%)\")\n",
    "print(f\"Saved to: ../data/cleaned_data.csv\")\n",
    "print(f\"Ready for exploratory data analysis!\")\n",
    "print(f\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
